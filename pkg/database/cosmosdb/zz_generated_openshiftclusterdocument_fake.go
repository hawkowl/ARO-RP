// Code generated by github.com/jim-minter/go-cosmosdb, DO NOT EDIT.

package cosmosdb

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"net/http"
	"sync"

	"github.com/ugorji/go/codec"

	pkg "github.com/Azure/ARO-RP/pkg/api"
)

type FakeOpenShiftClusterDocumentTrigger func(context.Context, *pkg.OpenShiftClusterDocument) error
type FakeOpenShiftClusterDocumentQuery func(OpenShiftClusterDocumentClient, *Query, *Options) OpenShiftClusterDocumentRawIterator

var _ OpenShiftClusterDocumentClient = &FakeOpenShiftClusterDocumentClient{}

func NewFakeOpenShiftClusterDocumentClient(h *codec.JsonHandle, uniqueKeys []string) *FakeOpenShiftClusterDocumentClient {
	return &FakeOpenShiftClusterDocumentClient{
		docs:       make(map[string][]byte),
		triggers:   make(map[string]FakeOpenShiftClusterDocumentTrigger),
		queries:    make(map[string]FakeOpenShiftClusterDocumentQuery),
		uniqueKeys: uniqueKeys,
		jsonHandle: h,
		lock:       &sync.RWMutex{},
		sorter:     func(in []*pkg.OpenShiftClusterDocument) {},
	}
}

type FakeOpenShiftClusterDocumentClient struct {
	docs       map[string][]byte
	jsonHandle *codec.JsonHandle
	lock       *sync.RWMutex
	triggers   map[string]FakeOpenShiftClusterDocumentTrigger
	queries    map[string]FakeOpenShiftClusterDocumentQuery
	uniqueKeys []string
	sorter     func([]*pkg.OpenShiftClusterDocument)

	// unavailable, if not nil, is an error to throw when attempting to
	// communicate with this Client
	unavailable error
}

func decodeOpenShiftClusterDocument(s []byte, handle *codec.JsonHandle) (*pkg.OpenShiftClusterDocument, error) {
	res := &pkg.OpenShiftClusterDocument{}
	err := codec.NewDecoder(bytes.NewBuffer(s), handle).Decode(&res)
	return res, err
}

func decodeOpenShiftClusterDocumentToMap(s []byte, handle *codec.JsonHandle) (map[interface{}]interface{}, error) {
	var res interface{}
	err := codec.NewDecoder(bytes.NewBuffer(s), handle).Decode(&res)
	if err != nil {
		return nil, err
	}
	ret, ok := res.(map[interface{}]interface{})
	if !ok {
		return nil, errors.New("Could not coerce")
	}
	return ret, err
}

func encodeOpenShiftClusterDocument(doc *pkg.OpenShiftClusterDocument, handle *codec.JsonHandle) (res []byte, err error) {
	buf := &bytes.Buffer{}
	err = codec.NewEncoder(buf, handle).Encode(doc)
	if err != nil {
		return
	}
	res = buf.Bytes()
	return
}

func (c *FakeOpenShiftClusterDocumentClient) MakeUnavailable(err error) {
	c.unavailable = err
}

func (c *FakeOpenShiftClusterDocumentClient) UseSorter(sorter func([]*pkg.OpenShiftClusterDocument)) {
	c.sorter = sorter
}

func (c *FakeOpenShiftClusterDocumentClient) encodeAndCopy(doc *pkg.OpenShiftClusterDocument) (*pkg.OpenShiftClusterDocument, []byte, error) {
	encoded, err := encodeOpenShiftClusterDocument(doc, c.jsonHandle)
	if err != nil {
		return nil, nil, err
	}
	res, err := decodeOpenShiftClusterDocument(encoded, c.jsonHandle)
	if err != nil {
		return nil, nil, err
	}
	return res, encoded, err
}

func (c *FakeOpenShiftClusterDocumentClient) Create(ctx context.Context, partitionkey string, doc *pkg.OpenShiftClusterDocument, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	if c.unavailable != nil {
		return nil, c.unavailable
	}
	c.lock.Lock()
	defer c.lock.Unlock()

	if options != nil {
		err := c.processPreTriggers(ctx, doc, options)
		if err != nil {
			return nil, err
		}
	}

	res, enc, err := c.encodeAndCopy(doc)
	if err != nil {
		return nil, err
	}
	docAsMap, err := decodeOpenShiftClusterDocumentToMap(enc, c.jsonHandle)
	if err != nil {
		return nil, err
	}

	for _, ext := range c.docs {
		extDecoded, err := decodeOpenShiftClusterDocumentToMap(ext, c.jsonHandle)
		if err != nil {
			return nil, err
		}

		for _, key := range c.uniqueKeys {
			var ourKeyStr string
			var theirKeyStr string
			ourKey, ourKeyOk := docAsMap[key]
			if ourKeyOk {
				ourKeyStr, ourKeyOk = ourKey.(string)
			}
			theirKey, theirKeyOk := extDecoded[key]
			if theirKeyOk {
				theirKeyStr, theirKeyOk = theirKey.(string)
			}
			if ourKeyOk && theirKeyOk && ourKeyStr != "" && ourKeyStr == theirKeyStr {
				return nil, &Error{
					StatusCode: http.StatusPreconditionFailed,
					Message:    "Entity with the specified id already exists in the system",
				}
			}
		}
	}

	c.docs[doc.ID] = enc
	return res, nil
}

func (c *FakeOpenShiftClusterDocumentClient) List(*Options) OpenShiftClusterDocumentIterator {
	if c.unavailable != nil {
		return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(c.unavailable)
	}
	c.lock.RLock()
	defer c.lock.RUnlock()

	docs := make([]*pkg.OpenShiftClusterDocument, 0, len(c.docs))
	for _, d := range c.docs {
		r, err := decodeOpenShiftClusterDocument(d, c.jsonHandle)
		if err != nil {
			return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(err)
		}
		docs = append(docs, r)
	}
	c.sorter(docs)
	return NewFakeOpenShiftClusterDocumentClientRawIterator(docs, 0)
}

func (c *FakeOpenShiftClusterDocumentClient) ListAll(context.Context, *Options) (*pkg.OpenShiftClusterDocuments, error) {
	if c.unavailable != nil {
		return nil, c.unavailable
	}
	c.lock.RLock()
	defer c.lock.RUnlock()

	openShiftClusterDocuments := &pkg.OpenShiftClusterDocuments{
		Count:                     len(c.docs),
		OpenShiftClusterDocuments: make([]*pkg.OpenShiftClusterDocument, 0, len(c.docs)),
	}

	for _, d := range c.docs {
		dec, err := decodeOpenShiftClusterDocument(d, c.jsonHandle)
		if err != nil {
			return nil, err
		}
		openShiftClusterDocuments.OpenShiftClusterDocuments = append(openShiftClusterDocuments.OpenShiftClusterDocuments, dec)
	}
	return openShiftClusterDocuments, nil
}

func (c *FakeOpenShiftClusterDocumentClient) Get(ctx context.Context, partitionkey string, documentId string, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	if c.unavailable != nil {
		return nil, c.unavailable
	}
	c.lock.RLock()
	defer c.lock.RUnlock()

	out, ext := c.docs[documentId]
	if !ext {
		return nil, &Error{StatusCode: http.StatusNotFound}
	}
	return decodeOpenShiftClusterDocument(out, c.jsonHandle)
}

func (c *FakeOpenShiftClusterDocumentClient) Replace(ctx context.Context, partitionkey string, doc *pkg.OpenShiftClusterDocument, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	if c.unavailable != nil {
		return nil, c.unavailable
	}
	c.lock.Lock()
	defer c.lock.Unlock()

	_, exists := c.docs[doc.ID]
	if !exists {
		return nil, &Error{StatusCode: http.StatusNotFound}
	}

	if options != nil {
		err := c.processPreTriggers(ctx, doc, options)
		if err != nil {
			return nil, err
		}
	}

	res, enc, err := c.encodeAndCopy(doc)
	if err != nil {
		return nil, err
	}
	c.docs[doc.ID] = enc
	return res, nil
}

func (c *FakeOpenShiftClusterDocumentClient) Delete(ctx context.Context, partitionKey string, doc *pkg.OpenShiftClusterDocument, options *Options) error {
	if c.unavailable != nil {
		return c.unavailable
	}
	c.lock.Lock()
	defer c.lock.Unlock()

	_, ext := c.docs[doc.ID]
	if !ext {
		return &Error{StatusCode: http.StatusNotFound}
	}

	delete(c.docs, doc.ID)
	return nil
}

func (c *FakeOpenShiftClusterDocumentClient) ChangeFeed(*Options) OpenShiftClusterDocumentIterator {
	if c.unavailable != nil {
		return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(c.unavailable)
	}
	return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(ErrNotImplemented)
}

func (c *FakeOpenShiftClusterDocumentClient) processPreTriggers(ctx context.Context, doc *pkg.OpenShiftClusterDocument, options *Options) error {
	for _, trigger := range options.PreTriggers {
		trig, ok := c.triggers[trigger]
		if ok {
			err := trig(ctx, doc)
			if err != nil {
				return err
			}
		} else {
			return ErrNotImplemented
		}
	}
	return nil
}

func (c *FakeOpenShiftClusterDocumentClient) Query(name string, query *Query, options *Options) OpenShiftClusterDocumentRawIterator {
	if c.unavailable != nil {
		return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(c.unavailable)
	}
	c.lock.RLock()
	defer c.lock.RUnlock()

	quer, ok := c.queries[query.Query]
	if ok {
		return quer(c, query, options)
	} else {
		return NewFakeOpenShiftClusterDocumentClientErroringRawIterator(ErrNotImplemented)
	}
}

func (c *FakeOpenShiftClusterDocumentClient) QueryAll(ctx context.Context, partitionkey string, query *Query, options *Options) (*pkg.OpenShiftClusterDocuments, error) {
	if c.unavailable != nil {
		return nil, c.unavailable
	}
	c.lock.RLock()
	defer c.lock.RUnlock()

	quer, ok := c.queries[query.Query]
	if ok {
		items := quer(c, query, options)
		res := &pkg.OpenShiftClusterDocuments{}
		err := items.NextRaw(ctx, -1, res)
		return res, err
	} else {
		return nil, ErrNotImplemented
	}
}

func (c *FakeOpenShiftClusterDocumentClient) InjectTrigger(trigger string, impl FakeOpenShiftClusterDocumentTrigger) {
	c.triggers[trigger] = impl
}

func (c *FakeOpenShiftClusterDocumentClient) InjectQuery(query string, impl FakeOpenShiftClusterDocumentQuery) {
	c.queries[query] = impl
}

// NewFakeOpenShiftClusterDocumentClientRawIterator creates a RawIterator that will produce only
// OpenShiftClusterDocuments from Next() and NextRaw().
func NewFakeOpenShiftClusterDocumentClientRawIterator(docs []*pkg.OpenShiftClusterDocument, continuation int) OpenShiftClusterDocumentRawIterator {
	return &fakeOpenShiftClusterDocumentClientRawIterator{docs: docs, continuation: continuation}
}

type fakeOpenShiftClusterDocumentClientRawIterator struct {
	docs         []*pkg.OpenShiftClusterDocument
	continuation int
}

func (i *fakeOpenShiftClusterDocumentClientRawIterator) Next(ctx context.Context, maxItemCount int) (*pkg.OpenShiftClusterDocuments, error) {
	out := &pkg.OpenShiftClusterDocuments{}
	err := i.NextRaw(ctx, maxItemCount, out)

	if out.Count == 0 {
		return nil, nil
	}
	return out, err
}

func (i *fakeOpenShiftClusterDocumentClientRawIterator) NextRaw(ctx context.Context, maxItemCount int, out interface{}) error {
	if i.continuation >= len(i.docs) {
		return nil
	}

	var docs []*pkg.OpenShiftClusterDocument
	if maxItemCount == -1 {
		docs = i.docs[i.continuation:]
		i.continuation = len(i.docs)
	} else {
		max := i.continuation + maxItemCount
		if max > len(i.docs) {
			max = len(i.docs)
		}
		docs = i.docs[i.continuation:max]
		i.continuation += max
	}

	d := out.(*pkg.OpenShiftClusterDocuments)
	d.OpenShiftClusterDocuments = docs
	d.Count = len(d.OpenShiftClusterDocuments)
	return nil
}

func (i *fakeOpenShiftClusterDocumentClientRawIterator) Continuation() string {
	if i.continuation >= len(i.docs) {
		return ""
	}
	return fmt.Sprintf("%d", i.continuation)
}

// fakeOpenShiftClusterDocumentErroringRawIterator is a RawIterator that will return an error on use.
func NewFakeOpenShiftClusterDocumentClientErroringRawIterator(err error) *fakeOpenShiftClusterDocumentErroringRawIterator {
	return &fakeOpenShiftClusterDocumentErroringRawIterator{err: err}
}

type fakeOpenShiftClusterDocumentErroringRawIterator struct {
	err error
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) Next(ctx context.Context, maxItemCount int) (*pkg.OpenShiftClusterDocuments, error) {
	return nil, i.err
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) NextRaw(context.Context, int, interface{}) error {
	return i.err
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) Continuation() string {
	return ""
}
